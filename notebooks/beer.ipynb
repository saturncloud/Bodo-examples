{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example analyzes beer reviews to find the most common words used in positive and negative reviews.\n",
    "Original example can be found [here](https://medium.com/rapids-ai/real-data-has-strings-now-so-do-gpus-994497d55f8e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on running these queries:\n",
    "\n",
    "By defaults runs use Bodo. Hence, data is distributed in chunks across processes.\n",
    "\n",
    "reviews_sample.csv size is 23.1MB\n",
    "\n",
    "Fulldataset is available on \"s3://bodo-examples-data/beer/reviews.csv\" and its size is 2.2GB\n",
    "\n",
    "To run the code:\n",
    "1. Make sure you [add your AWS account credentials to Saturn Cloud](https://saturncloud.io/docs/examples/python/load-data/qs-load-data-s3/#create-aws-credentials) to access the data.\n",
    "2. If you want to run the example using pandas only (without Bodo):\n",
    "    1. Comment lines magic expression (`%%px`) and bodo decorator (`@bodo.jit`) from all the code cells.\n",
    "    2. Then, re-run cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bd502-c7df-4693-ad91-32abacc66be8",
   "metadata": {},
   "source": [
    "### Start an IPyParallel cluster\n",
    "Run the following code in a cell to start an IPyParallel cluster. 4 cores are used in this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85ae9e-883f-454c-a860-a9ab05065133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12engine/s]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "import psutil; n = min(psutil.cpu_count(logical=False), 8)\n",
    "rc = ipp.Cluster(engines='mpi', n=n).start_and_connect_sync(activate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f272c-f965-4764-bdba-d643bf6e6515",
   "metadata": {},
   "source": [
    "### Verifying your setup\n",
    "Run the following code to verify that your IPyParallel cluster is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c4772-a044-468b-851a-dc4672e07f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|                                                                                               | 0/8 [00:02<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:6] Hello World from rank 6. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Hello World from rank 0. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:7] Hello World from rank 7. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] Hello World from rank 3. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:5] Hello World from rank 5. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:4] Hello World from rank 4. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Hello World from rank 1. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|███████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.81tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] Hello World from rank 2. Total ranks=8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import bodo\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-enzyme",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - scikit-learn to build and evaluate classification models\n",
    " - xgboost for xgboost classifier model algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import bodo\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler # data normalization\n",
    "from sklearn.model_selection import train_test_split # data split\n",
    "from sklearn.linear_model import LogisticRegression # Logistic regression algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest tree algorithm\n",
    "from xgboost import XGBClassifier # XGBoost algorithm\n",
    "from sklearn.svm import LinearSVC # SVM classification algorithm\n",
    "from sklearn.metrics import accuracy_score # evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-daughter",
   "metadata": {},
   "source": [
    "## Data Processing and EDA\n",
    "1. Load dataset\n",
    "2. Compute the percentage of fraud cases in the overall recorded transcations.\n",
    "3. Get a statistical view of both fraud and non-fraud transaction amount data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "1. Create lists of stopwords and punctuation that will be removed.\n",
    "2. Define regex that will be used to remove these punctuation and stopwords from the reviews.\n",
    "3. Use the lower and strip functions to convert all letters to lowercase and remove excess whitespace. \n",
    "4. Remove stopwords and punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "with open(\"nltk-stopwords.txt\", \"r\") as fh:\n",
    "    STOPWORDS = list(map(str.strip, fh.readlines()))\n",
    "\n",
    "\n",
    "PUNCT_LIST = [\"\\.\", \"\\-\", \"\\?\", \"\\:\", \":\", \"!\", \"&\", \"'\", \",\"]\n",
    "punc_regex = \"|\".join([f\"({p})\" for p in PUNCT_LIST])\n",
    "stopword_regex = \"|\".join([f\"\\\\b({s})\\\\b\" for s in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"reviews\"])\n",
    "def preprocess(reviews):\n",
    "    # lowercase and strip\n",
    "    reviews = reviews.str.lower()\n",
    "    reviews = reviews.str.strip()\n",
    "\n",
    "    # remove punctuation and stopwords\n",
    "    reviews = reviews.str.replace(punc_regex, \"\", regex=True)\n",
    "    reviews = reviews.str.replace(stopword_regex, \"\", regex=True)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "BodoWarning: Unable to get S3 Bucket Region.\n",
      "'coroutine' object is not subscriptable.\n",
      "Will use the value defined in the AWS_DEFAULT_REGION environment variable (or us-east-1 if that is not provided either).\n",
      "read time 0.8933188915252686\n",
      "preprocess time 6.139484882354736\n",
      "high/low time 0.0021250247955322266\n",
      "value_counts time 0.006670951843261719\n",
      "total time 7.042609930038452\n",
      "beer         333\n",
      "one          158\n",
      "taste        140\n",
      "head         119\n",
      "like         117\n",
      "best         102\n",
      "chocolate     90\n",
      "dark          90\n",
      "great         86\n",
      "perfect       80\n",
      "good          79\n",
      "sweet         77\n",
      "smell         73\n",
      "bottle        72\n",
      "ive           70\n",
      "flavor        68\n",
      "glass         65\n",
      "well          65\n",
      "ever          65\n",
      "aroma         64\n",
      "nice          64\n",
      "malt          63\n",
      "bourbon       62\n",
      "hops          62\n",
      "beers         62\n",
      "dtype: int64\n",
      "beer           239\n",
      "like           109\n",
      "taste          104\n",
      "head            69\n",
      "light           65\n",
      "one             65\n",
      "smell           57\n",
      "bad             53\n",
      "bottle          52\n",
      "really          49\n",
      "good            41\n",
      "would           40\n",
      "get             38\n",
      "water           35\n",
      "flavor          33\n",
      "much            32\n",
      "carbonation     32\n",
      "smells          32\n",
      "beers           32\n",
      "corn            31\n",
      "glass           31\n",
      "even            31\n",
      "poured          30\n",
      "tastes          29\n",
      "drink           29\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "@bodo.jit\n",
    "def find_top_words(review_filename):\n",
    "    # Load in the data\n",
    "    t_start = time.time()\n",
    "    df = pd.read_csv(review_filename, parse_dates=[2])\n",
    "    print(\"read time\", time.time() - t_start)\n",
    "\n",
    "    score = df.score\n",
    "    reviews = df.text\n",
    "\n",
    "    t1 = time.time()\n",
    "    reviews = preprocess(reviews)\n",
    "    print(\"preprocess time\", time.time() - t1)\n",
    "\n",
    "    t1 = time.time()\n",
    "    # create low and high score series\n",
    "    low_threshold = 1.5\n",
    "    high_threshold = 4.95\n",
    "    high_reviews = reviews[score > high_threshold]\n",
    "    low_reviews = reviews[score <= low_threshold]\n",
    "    high_reviews = high_reviews.dropna()\n",
    "    low_reviews = low_reviews.dropna()\n",
    "\n",
    "    high_colsplit = high_reviews.str.split()\n",
    "    low_colsplit = low_reviews.str.split()\n",
    "    print(\"high/low time\", time.time() - t1)\n",
    "\n",
    "    t1 = time.time()\n",
    "    high_words = high_colsplit.explode()\n",
    "    low_words = low_colsplit.explode()\n",
    "\n",
    "    top_words = high_words.value_counts().head(25)\n",
    "    low_words = low_words.value_counts().head(25)\n",
    "    print(\"value_counts time\", time.time() - t1)\n",
    "    print(\"total time\", time.time() - t_start)\n",
    "\n",
    "    print(top_words)\n",
    "    print(low_words)\n",
    "    \n",
    "find_top_words(\"s3://bodo-examples-data/beer/reviews_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
