{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Parking Violations\n",
    "This example demonstrates ETL operations for transforming New York City parking summons data to create maps. \n",
    "\n",
    "Original example can be found [here](https://github.com/JBlumstein/NYCParking/blob/master/NYC_Parking_Violations_Mapping_Example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on running these queries:\n",
    "\n",
    "Bodo is used by defaults, which distributes data chunks across cores automatically.\n",
    "\n",
    "Using 2016 and 2017 dataset [here](https://www.kaggle.com/new-york-city/nyc-parking-tickets) which is ~4GB.\n",
    "\n",
    "\n",
    "To run the code:\n",
    "1. Make sure you [add your AWS account credentials to Saturn Cloud](https://saturncloud.io/docs/examples/python/load-data/qs-load-data-s3/#create-aws-credentials) to access the data.\n",
    "2. If you want to run a query in regular pandas:\n",
    "    1. Comment lines with Jupyter parallel magic (%%px) and bodo decorator (@bodo.jit) from all the code cells.\n",
    "    2. Then, re-run cells from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start an IPyParallel cluster\n",
    "Run the following code in a cell to start an IPyParallel cluster. 4 cores are used in this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "\n",
    "import psutil\n",
    "\n",
    "n = min(psutil.cpu_count(logical=False), 8)\n",
    "rc = ipp.Cluster(engines=\"mpi\", n=n).start_and_connect_sync(activate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying your setup\n",
    "Run the following code to verify that your IPyParallel cluster is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import bodo\n",
    "\n",
    "print(f\"Hello World from rank {bodo.get_rank()}. Total ranks={bodo.get_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Packages\n",
    "\n",
    "These are the main packages we are going to work with:\n",
    " - Bodo to parallelize Python code automatically\n",
    " - Pandas to work with data\n",
    " - Numpy to work with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "import bodo\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "In this section parking tickets data is loaded from S3 bucket and aggregated by day, violation type, and police precinct and placed in a dataframe. \n",
    "\n",
    "Each dataframe is added to a list of dataframes, and then the dataframes are all appended into a single dataframe named `main_df`.\n",
    "\n",
    "In addition, violcation codes, and precincts information are loaded as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "\n",
    "@bodo.jit(distributed=[\"many_year_df\"], cache=True)\n",
    "def load_parking_tickets():\n",
    "    start = time.time()\n",
    "    year_2016_df = pd.read_csv(\n",
    "        \"s3://bodo-examples-data/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2016.csv\",\n",
    "        parse_dates=[\"Issue Date\"],\n",
    "    )\n",
    "    year_2016_df = year_2016_df.groupby(\n",
    "        [\"Issue Date\", \"Violation County\", \"Violation Precinct\", \"Violation Code\"],\n",
    "        as_index=False,\n",
    "    )[\"Summons Number\"].count()\n",
    "\n",
    "    year_2017_df = pd.read_csv(\n",
    "        \"s3://bodo-examples-data/nyc-parking-tickets/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\",\n",
    "        parse_dates=[\"Issue Date\"],\n",
    "    )\n",
    "    year_2017_df = year_2017_df.groupby(\n",
    "        [\"Issue Date\", \"Violation County\", \"Violation Precinct\", \"Violation Code\"],\n",
    "        as_index=False,\n",
    "    )[\"Summons Number\"].count()\n",
    "\n",
    "    # concatenate all dataframes into one dataframe\n",
    "    many_year_df = pd.concat([year_2016_df, year_2017_df])\n",
    "    end = time.time()\n",
    "    print(\"Reading Time: \", end - start)\n",
    "    print(many_year_df.head())\n",
    "    return many_year_df\n",
    "\n",
    "\n",
    "main_df = load_parking_tickets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit\n",
    "def load_violation_precincts_codes():\n",
    "    start = time.time()\n",
    "    violation_codes = pd.read_csv(\"./DOF_Parking_Violation_Codes.csv\")\n",
    "    violation_codes.columns = [\n",
    "        \"Violation Code\",\n",
    "        \"Definition\",\n",
    "        \"manhattan_96_and_below\",\n",
    "        \"all_other_areas\",\n",
    "    ]\n",
    "    nyc_precincts_df = pd.read_csv(\"./nyc_precincts.csv\", index_col=\"index\")\n",
    "    end = time.time()\n",
    "    print(\"Violation and precincts load Time: \", end - start)\n",
    "    return violation_codes, nyc_precincts_df\n",
    "\n",
    "\n",
    "violation_codes, nyc_precincts_df = load_violation_precincts_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "1. Remove summons with undefined violations (violation code 36).\n",
    "2. Delete entries that have dates not within our dataset dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"main_df\"], cache=True)\n",
    "def elim_code_36(main_df):\n",
    "    start = time.time()\n",
    "    \"\"\"function to take out all violations with code 36 (other)\"\"\"\n",
    "    main_df = main_df[main_df[\"Violation Code\"] != 36].sort_values(\n",
    "        \"Summons Number\", ascending=False\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(\"Eliminate undefined violations time: \", end - start)\n",
    "    print(main_df.head())\n",
    "    return main_df\n",
    "\n",
    "\n",
    "main_df = elim_code_36(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"main_df\"], cache=True)\n",
    "def remove_outliers(main_df):\n",
    "    start = time.time()\n",
    "    main_df = main_df[\n",
    "        (main_df[\"Issue Date\"] >= \"2016-01-01\")\n",
    "        & (main_df[\"Issue Date\"] <= \"2017-12-31\")\n",
    "    ]\n",
    "    end = time.time()\n",
    "    print(\"Remove outliers time: \", (end - start))\n",
    "    print(main_df.head())\n",
    "    return main_df\n",
    "\n",
    "\n",
    "main_df = remove_outliers(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect More Information\n",
    "Data on each violation type, like ticket cost and violation descriptions, are added to the dataset by joining our main_df dataset with a violation type level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "@bodo.jit(distributed=[\"main_df\"], cache=True)\n",
    "def merge_violation_code(main_df):\n",
    "    start = time.time()\n",
    "    # left join main_df and violation_codes df so that there's more info on violation in main_df\n",
    "    main_df = pd.merge(main_df, violation_codes, on=\"Violation Code\", how=\"left\")\n",
    "    # cast precincts as integers from floats (inadvertent type change by merge)\n",
    "    main_df[\"Violation Precinct\"] = main_df[\"Violation Precinct\"].astype(int)\n",
    "    end = time.time()\n",
    "    print(\"Merge time: \", (end - start))\n",
    "    print(main_df.head())\n",
    "    return main_df\n",
    "\n",
    "\n",
    "main_df = merge_violation_code(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost of Summons For Each Precinct.\n",
    "\n",
    "1. Most violations have different ticket prices, based on whether they occur in Manhattan below 96th St. or elsewhere in New York City. The daily revenue for each violation type in each precinct are determined by multiplying the number of offenses by the average cost of the offense (based on how much of the precinct is in Manhattan below 96th St.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# calculate the total summonses in dollars for a violation in a precinct on a day\n",
    "@bodo.jit(distributed=[\"main_df\"], cache=True)\n",
    "def calculate_total_summons(main_df):\n",
    "    start = time.time()\n",
    "    # create column for portion of precinct 96th st. and below\n",
    "    n = len(main_df)\n",
    "    portion_manhattan_96_and_below = np.empty(n, np.int64)\n",
    "    # NOTE: To run pandas, use this loop.\n",
    "    # for i in range(n):\n",
    "    for i in bodo.prange(n):\n",
    "        x = main_df[\"Violation Precinct\"].iat[i]\n",
    "        if x < 22 or x == 23:\n",
    "            portion_manhattan_96_and_below[i] = 1.0\n",
    "        elif x == 22:\n",
    "            portion_manhattan_96_and_below[i] = 0.75\n",
    "        elif x == 24:\n",
    "            portion_manhattan_96_and_below[i] = 0.5\n",
    "        else:  # other\n",
    "            portion_manhattan_96_and_below[i] = 0\n",
    "    main_df[\"portion_manhattan_96_and_below\"] = portion_manhattan_96_and_below\n",
    "\n",
    "    # create column for average dollar amount of summons based on location\n",
    "    main_df[\"average_summons_amount\"] = (\n",
    "        main_df[\"portion_manhattan_96_and_below\"] * main_df[\"manhattan_96_and_below\"]\n",
    "        + (1 - main_df[\"portion_manhattan_96_and_below\"]) * main_df[\"all_other_areas\"]\n",
    "    )\n",
    "\n",
    "    # get total summons dollars by multiplying average dollar amount by number of summons given\n",
    "    main_df[\"total_summons_dollars\"] = (\n",
    "        main_df[\"Summons Number\"] * main_df[\"average_summons_amount\"]\n",
    "    )\n",
    "    main_df = main_df.sort_values(by=[\"total_summons_dollars\"], ascending=False)\n",
    "    end = time.time()\n",
    "    print(\"Calculate Total Summons Time: \", (end - start))\n",
    "    print(main_df.head())\n",
    "    return main_df\n",
    "\n",
    "\n",
    "main_df = calculate_total_summons(main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The aggregate function aggregates main_df by precinct. Once the data is run through this function that it will have a single row per precinct with the precinct number, the number of summonses, and the combined dollar value of the summonses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "\n",
    "@bodo.jit(distributed=[\"main_df\", \"precinct_offenses_df\"], cache=True)\n",
    "def aggregate(main_df):\n",
    "    \"\"\"function that aggregates and filters data\n",
    "    e.g. total violations by precinct\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    filtered_dataset = main_df[\n",
    "        [\"Violation Precinct\", \"Summons Number\", \"total_summons_dollars\"]\n",
    "    ]\n",
    "    precinct_offenses_df = (\n",
    "        filtered_dataset.groupby(by=[\"Violation Precinct\"])\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .fillna(0)\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(\"Aggregate code time: \", (end - start))\n",
    "    print(precinct_offenses_df.head())\n",
    "    return precinct_offenses_df\n",
    "\n",
    "\n",
    "precinct_offenses_df = aggregate(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop the cluster run the following command.\n",
    "rc.cluster.stop_cluster_sync()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
